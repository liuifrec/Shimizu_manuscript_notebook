{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  scRNASeq Downstream analysis pipeline functions\n",
    "\n",
    "* This is supposed to be the bench for the callable functions to be used in the future analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running scvelo 0.2.4 (python 3.10.6) on 2022-10-20 16:55.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: XMLRPC request failed [code: -32500]\n",
      "RuntimeError: PyPI's XMLRPC API is currently disabled due to unmanageable load and will be deprecated in the near future. See https://status.python.org/ for more information.\n"
     ]
    }
   ],
   "source": [
    "import scvelo as scv\n",
    "scv.logging.print_version()\n",
    "import warnings\n",
    "import scirpy as ir\n",
    "import scanpy as sc\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rcParams\n",
    "from matplotlib import colors\n",
    "import seaborn as sb\n",
    "import bbknn\n",
    "import logging\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from scipy.stats     import norm\n",
    "import glob\n",
    "import os\n",
    "\n",
    "from scipy import sparse\n",
    "import scanpy.external as sce\n",
    "\n",
    "import scanorama\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nimport hvplot.pandas\\nimport docx\\nfrom docx import Document\\nfrom docx.shared import Inches\\nfrom docx.shared import Pt\\nimport holoviews as hv\\nimport panel as pn\\nimport bokeh\\nfrom bokeh.resources import INLINE\\nimport gseapy\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "import hvplot.pandas\n",
    "import docx\n",
    "from docx import Document\n",
    "from docx.shared import Inches\n",
    "from docx.shared import Pt\n",
    "import holoviews as hv\n",
    "import panel as pn\n",
    "import bokeh\n",
    "from bokeh.resources import INLINE\n",
    "import gseapy\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data IO and Integration\n",
    "\n",
    "## New version of the I/O takes \n",
    "\n",
    "* Input pathway\n",
    "* A dictionary of Samples \n",
    "* Platform of the scRNASeq used, current default 10x \n",
    "\n",
    "## Returns\n",
    "\n",
    "* A list of adata file with integration of potentially:\n",
    "    1. TCR/BCR files\n",
    "    2. Velocity loom files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#File I/O\n",
    "def data_IO(samples,In_path,Platform = '10x_gex', IG = True,Velo=True):\n",
    "    adatalist = []\n",
    "    for sample, sample_meta in samples.items():\n",
    "        gex_file = In_path+sample+'/outs/filtered_feature_bc_matrix.h5'\n",
    "        if  Velo:\n",
    "            loom_file = In_path+sample+'/velocyto/'+sample+'.loom'\n",
    "            ldata = scv.read(loom_file, cache=True)\n",
    "        if Platform == '10x_gex':\n",
    "            adata = sc.read_10x_h5(gex_file, gex_only=False)\n",
    "        \n",
    "        if IG:\n",
    "            tcr_file = In_path+sample_meta[\"TCR\"]+'/outs/filtered_contig_annotations.csv'\n",
    "            bcr_file = In_path+sample_meta[\"BCR\"]+'/outs/filtered_contig_annotations.csv'\n",
    "            adata_tcr = ir.io.read_10x_vdj(tcr_file)\n",
    "            adata_bcr = ir.io.read_10x_vdj(bcr_file)\n",
    "            ir.pp.merge_with_ir(adata, adata_bcr)\n",
    "            adata.obs[\"is_cell\"] = \"None\"\n",
    "            adata_tcr.obs[\"is_cell\"] = \"None\"\n",
    "            adata.obs[\"high_confidence\"] = \"None\"\n",
    "            adata_tcr.obs[\"high_confidence\"] = \"None\"\n",
    "            ir.pp.merge_airr_chains(adata, adata_tcr)\n",
    "\n",
    "        if  Velo:\n",
    "            adata = scv.utils.merge(adata, ldata)\n",
    "        adata.var_names_make_unique()\n",
    "        adata.obs[\"Sample\"] = sample\n",
    "        \n",
    "        adatalist.append(adata)\n",
    "    return adatalist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unify_value(adatalist):\n",
    "    uniset = set(adatalist[0].var_names)\n",
    "    for adata in adatalist:\n",
    "        uniset = uniset.intersection(set(adata.var_names))\n",
    "        sample_tag = adata.obs[\"Sample\"][0] \n",
    "        \n",
    "    x = [g for g in uniset]\n",
    "    gex = adatalist[0].concatenate(*adatalist[1:], join='outer')\n",
    "    gex = gex[:,x]\n",
    "    return gex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sparse and Dense matrix conversion\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binarization of properities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Thrshold_by_Gaussian_with_plot(adata, tag, out_path,  sample_tag, sparse = True):\n",
    "    if tag in adata.obs.columns:\n",
    "        data = adata.obs[tag].to_numpy().reshape(len(adata.obs[tag]),1)\n",
    "    elif (sparse):\n",
    "        data = adata[:, tag].X.A\n",
    "        data =  np.interp(data, (data.min(), data.max()), (0, 10))\n",
    "    else:\n",
    "        data = adata[:, tag].X\n",
    "        data =  np.interp(data, (data.min(), data.max()), (0, 10))\n",
    "    \n",
    "    N = len(data)\n",
    "    \n",
    "   \n",
    "    x = np.linspace(0, 10, N+1)\n",
    "    gmm = GaussianMixture(n_components=2, covariance_type='spherical')\n",
    "    gmm.fit(data)\n",
    "    mu1 = gmm.means_[0, 0]\n",
    "    mu2 = gmm.means_[1, 0]\n",
    "\n",
    "    var1, var2 = gmm.covariances_\n",
    "    wgt1, wgt2 = gmm.weights_\n",
    "    cut_off = (mu2 + mu1)/2\n",
    "    delta  = abs(mu2 - mu1)\n",
    "    var = (var1+var2)/2\n",
    "    #data[data == 0] = np.nan\n",
    "    outfile =out_path+'/figures/'+sample_tag+'_'+tag +'_Gaussian_Mixture_Model.png'\n",
    "    plt.hist(data[data>0.1],bins='auto')\n",
    "    plt.axvline(mu1,  color = 'y',linestyle=\":\",label='Fitted Mean 1')\n",
    "    plt.axvline(mu2,  color = 'g',linestyle=\":\",label='Fitted Mean 2')\n",
    "    plt.axvline(cut_off,  color = 'r', label='Threshold ')\n",
    "    plt.legend()\n",
    "    plt.title(sample_tag+' '+tag + ' Gaussian Mixture Model')\n",
    "    plt.savefig(outfile)\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    up_bound = max([mu1,mu2])\n",
    "    low_bound = min([mu1,mu2])\n",
    "    return [delta, var, cut_off,up_bound,low_bound]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quality Control\n",
    "\n",
    "## Adding Doublet Identification procedure into the QC steps\n",
    "\n",
    "* Start from scrublet\n",
    "\n",
    "## Additional feature percentage calculation\n",
    "\n",
    "* Percentage of Ribosome RNA\n",
    "* Percentage of Himoglobin\n",
    "\n",
    "\n",
    "\n",
    "## Can not keep all the cell and genes without filtration\n",
    "\n",
    "* Check the effects of removing the cells or not is a different story\n",
    "\n",
    "\n",
    "## Label them through threshold determination\n",
    "\n",
    "* High concentration of mitochrondria \n",
    "* Highest read counts\n",
    "* Hemoglobin contamination \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def qc_and_preprocess(adata, out_path, feature_tag = {'mt':'MT-','ribo':(\"RPS\",\"RPL\"),'hb':(\"HB\")},\n",
    "                      multi_sample=False, organism = \"hsapiens\"): \n",
    "    adata.var_names_make_unique()\n",
    "    sc.pl.highest_expr_genes(adata, n_top=20, save='_before_filter.png')\n",
    "    mito_tag = feature_tag['mt']\n",
    "    for feature in feature_tag.keys():\n",
    "        feature_genes = adata.var_names.str.startswith(feature_tag[feature]) \n",
    "        tag = 'pct_counts_'+str(feature)\n",
    "        adata.obs[tag] = np.sum(\n",
    "        adata[:, feature_genes].X, axis=1).A1 / np.sum(adata.X, axis=1).A1\n",
    "    scrub_result = sce.pp.scrublet(adata,copy=True,threshold=0.5)\n",
    "    adata.obs = scrub_result.obs\n",
    "# for each cell compute fraction of counts in mito genes vs. all genes\n",
    "# the `.A1` is only necessary as X is sparse (to transform to a dense array after summing)\n",
    "#Convert all matrix into sparse matrix\n",
    "    \n",
    "# add the total counts per cell as observations-annotation to adata\n",
    "    adata.obs['n_counts'] = adata.X.sum(axis=1).A1\n",
    "    adata.obs['n_genes'] = (adata.X > 0).sum(axis=1).A1\n",
    "  \n",
    "    sc.pp.calculate_qc_metrics(adata,  inplace=True)\n",
    "    sb.jointplot(data=adata.obs,\n",
    "        x=\"log1p_total_counts\", y=\"log1p_n_genes_by_counts\",  kind=\"hex\"\n",
    "    )\n",
    "    plt.savefig(out_path+'/figures/QC_hex.png')\n",
    "    plt.close()\n",
    "    %matplotlib inline\n",
    "    sc.pl.violin(adata, ['n_genes', 'n_counts', 'doublet_score','pct_counts_mt','pct_counts_ribo', 'pct_counts_hb'],\n",
    "                 jitter=0.4, multi_panel=True, save= '_QC_of_entire_set')\n",
    "    adata.obs['log_counts'] = np.log(adata.obs['n_counts'])\n",
    "    #Quality control - plot QC metrics\n",
    "    #Sample quality plots\n",
    "    #Beginning of the subsection\n",
    "\n",
    "    if multi_sample:\n",
    "        t1 = sc.pl.violin(adata, 'n_counts', groupby='Sample', size=2, log=True, cut=0,save = '_QC_by_sample_1.png',rotation = 90)\n",
    "        t2 = sc.pl.violin(adata, 'pct_counts_mt', groupby='Sample',save = '_QC_by_sample_2.png',rotation = 90)\n",
    "        sc.pl.violin(adata, 'pct_counts_ribo', groupby='Sample',save = '_QC_by_sample_3.png',rotation = 90)\n",
    "        sc.pl.violin(adata,'pct_counts_hb', groupby='Sample',save = '_QC_by_sample_4.png',rotation = 90)\n",
    "        t3 = sc.pl.violin(adata, 'doublet_score', groupby='Sample',save = '_scrublet_sample.png',rotation = 90)\n",
    "        t4 = sc.pl.scatter(adata, x='total_counts', y='pct_counts_mt', color=\"Sample\")\n",
    " \n",
    "    \n",
    "    sc.pl.scatter(adata, 'n_counts', 'pct_counts_mt',save = '_count_to_mito_1.png')\n",
    "    p1 = sc.pl.scatter(adata, 'n_counts', 'n_genes', color='pct_counts_mt',save ='_count_to_gene.png')\n",
    "    #Scatter plot zoom into the n_counts within the threshold\n",
    "    #p2 = sc.pl.scatter(adata[adata.obs['n_counts']<10000], 'n_counts', 'n_genes', color='percent_mito',save ='_count_to_gene_threshold.png')\n",
    "    #Thresholding decision: counts\n",
    "    p3 = sb.distplot(adata.obs['n_counts'], kde=False)\n",
    "    \n",
    "    \n",
    "    \n",
    "    #Distribution plots \n",
    "    plt.savefig(out_path+'/figures/read_count_distribution.png')\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "#Thresholding decision: genes\n",
    "    p6 = sb.distplot(adata.obs['n_genes'], kde=False, bins=100)\n",
    "    plt.savefig(out_path+'/figures/n_genes_distribution.png')\n",
    "    plt.show()\n",
    "    plt.close()\n",
    " # Filter cells according to identified QC thresholds:\n",
    "    delta, var, cut_off,up_bound,low_bound= Thrshold_by_Gaussian_with_plot(adata, 'pct_counts_mt', out_path, 'All_samples', sparse = False)\n",
    "    mito_cut = cut_off\n",
    "    \n",
    "    delta, var, cut_off,up_bound,low_bound= Thrshold_by_Gaussian_with_plot(adata, 'n_counts', out_path, 'All_samples', sparse = False)\n",
    "    count_up = int(up_bound+var)\n",
    "    count_low = int(low_bound/16)\n",
    "    \n",
    "    delta, var, cut_off,up_bound,low_bound= Thrshold_by_Gaussian_with_plot(adata, 'n_genes', out_path, 'All_samples', sparse = False)\n",
    "    gene_up = int(up_bound+delta)\n",
    "    gene_low = int(low_bound/4)\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    origin = adata.n_obs\n",
    "    \n",
    "    sc.pp.filter_cells(adata, min_counts = count_low)\n",
    "    c1 =  origin - adata.n_obs \n",
    "    origin = adata.n_obs\n",
    "    print('filtered out {:d} cells that have less than {:d} counts'.format(c1,count_low))\n",
    "    ogene= adata.n_vars\n",
    "    sc.pp.filter_genes(adata, min_cells=3)\n",
    "    g1 = ogene - adata.n_vars\n",
    "    ogene = adata.n_vars\n",
    "    print('filtered out {:d} genes that are detected in less than 3 cells'.format(g1))\n",
    "    \n",
    "\n",
    "    sc.pp.filter_cells(adata, max_counts = count_up)\n",
    "    c2 = origin - adata.n_obs  \n",
    "    origin = adata.n_obs\n",
    "    print('filtered out {:d} cells that have more than {:d} counts'.format(c2,count_up))\n",
    "\n",
    "    adata = adata[adata.obs['pct_counts_mt'] <  mito_cut]\n",
    "    c3 = origin - adata.n_obs  \n",
    "    origin = adata.n_obs\n",
    "    print('filtered out {:d} cells that has over {:d}% reads belong to mitochondrial genes'.format(c3,int(mito_cut*100)))\n",
    "\n",
    "   # adata = adata[adata.obs['pct_counts_ribo'] > 0.05, :]\n",
    "   # cx = origin - adata.n_obs\n",
    "   # origin = adata.n_obs\n",
    "   # print('filtered out {:d} cells that has less than 5% reads belong to ribosome genes'.format(cx))\n",
    "    #Change the threshold for Togashi dataset to avoid filter out 8k cells ~James\n",
    "    sc.pp.filter_cells(adata, min_genes = gene_low)\n",
    "    c4 =  origin - adata.n_obs  \n",
    "    origin = adata.n_obs\n",
    "    print('filtered out {:d} cells that have less than {:d} genes expressed'.format(c4,gene_low))\n",
    "    \n",
    "    adata = adata[adata.obs['n_genes'] < gene_up, :]\n",
    "    c5 =  origin - adata.n_obs  \n",
    "    origin = adata.n_obs\n",
    "    \n",
    "    print('filtered out {:d} cells that have over {:d} genes expressed'.format(c5,gene_up))\n",
    "    sc.pl.violin(adata, ['n_genes', 'n_counts', 'doublet_score','pct_counts_mt','pct_counts_ribo', 'pct_counts_hb'],\n",
    "                 jitter=0.4, multi_panel=True,save= '_QC_of_entire_set_after_filtration')\n",
    "    \n",
    "    return adata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalization and Feature Selection\n",
    "\n",
    "* Should add the process of imputation here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalization and preprocessing\n",
    "def feature_selection(adata, out_path, filter_genes, exclude = True):\n",
    "    sc.pp.normalize_total(adata, inplace=True)\n",
    "    #sc.pp.normalize_per_cell(adata, counts_per_cell_after=1e6)\n",
    "  \n",
    "    sc.pl.highest_expr_genes(adata, n_top=20, save='_after_QC.png')\n",
    "    if exclude:\n",
    "        kept =  ~adata.var_names.str.startswith('RPL')\n",
    "    \n",
    "        for fit in filter_genes:\n",
    "            fi_genes = ~adata.var_names.str.startswith(fit)\n",
    "            kept = kept & fi_genes\n",
    "        filtered = ~kept\n",
    "        filtered_genes =  adata[:, filtered].var_names\n",
    " \n",
    "        adata = adata[:, kept]\n",
    "    \n",
    "        sc.pl.highest_expr_genes(adata, n_top=20, save='_after_exclude.png')\n",
    "    adata.raw = adata\n",
    "    sc.pp.log1p(adata)\n",
    "   \n",
    "    sc.pp.highly_variable_genes(adata, flavor='cell_ranger', n_top_genes=4000)\n",
    "    print('\\n','Number of highly variable genes: {:d}'.format(np.sum(adata.var['highly_variable'])))\n",
    "    sc.pl.highly_variable_genes(adata, save='_highly_variable_genes.png')\n",
    "    sc.pp.scale(adata,  zero_center=False)\n",
    "    return adata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batch Correction\n",
    "\n",
    "## Scanorama Rocks!\n",
    "\n",
    "# Clustering and Dimentional Reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clustering(adata,samples,resol=1,multi = True): \n",
    "\n",
    "   # bbknn.bbknn(adata,batch_key='Sample')\n",
    "    if multi:\n",
    "        adatas = [adata[adata.obs['Sample']== x] for x in samples.keys()]\n",
    "        corrected = scanorama.correct_scanpy(adatas, return_dimred=True)\n",
    "        del adatas\n",
    "        corrected_X = corrected[0].concatenate(*corrected[1:], join='outer')\n",
    "        del corrected\n",
    "        adata.obsm[\"X_scanorama\"] = corrected_X.obsm[\"X_scanorama\"]\n",
    "        del corrected_X\n",
    "        sc.pp.neighbors(adata, use_rep=\"X_scanorama\")\n",
    "    \n",
    "        #sce.pp.scanorama_integrate(adata, 'Sample',batch_size=sample_counts)/\n",
    "        #sc.pp.neighbors(adata, use_rep='X_scanorama')\n",
    "    else:\n",
    "        sc.pp.pca(adata, n_comps=50, use_highly_variable=True, zero_center=False, svd_solver='arpack')\n",
    "        sc.pp.neighbors(adata)\n",
    "    \n",
    "    sc.tl.leiden(adata,resolution=resol)\n",
    "    #sc.tl.louvain(adata,resolution=2)\n",
    "    sc.tl.paga(adata, groups='leiden')\n",
    "    #sc.tl.tsne(adata, n_jobs=40) #Note n_jobs works for MulticoreTSNE, but not regular implementation)\n",
    "    #sc.tl.diffmap(adata)\n",
    "    #sc.tl.draw_graph(adata)\n",
    "    sc.pl.paga(adata,node_size_power= 1.0,threshold=0.1 ,edge_width_scale = 0.1,save ='_Graph.png') \n",
    " \n",
    "    # remove `plot=False` if you want to see the coarse-grained graph\n",
    "    sc.tl.umap(adata,  init_pos=sc.tl._utils.get_init_pos_from_paga(adata), maxiter=100,min_dist=0.1, spread=4.0)\n",
    "    \n",
    "    sc.pl.umap(adata, color='leiden', legend_loc='on data',legend_fontsize=10,save ='_Leiden_clustering.png') \n",
    "    if multi:\n",
    "        sc.pl.umap(adata, color='Sample')\n",
    "        adata.obs.groupby(['leiden'])['Sample'].value_counts(normalize = True).unstack().plot.bar(stacked=True)\n",
    "        ax = plt.subplot(111)\n",
    "        plt.ylabel('Composition of cells')\n",
    "        plt.xlabel('Leiden cluster')\n",
    "        box = ax.get_position()\n",
    "        ax.set_position([box.x0, box.y0, box.width * 0.8, box.height])\n",
    "        ax.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "\n",
    "        \n",
    "        adata.obs.groupby(['leiden'])['Sample'].value_counts().unstack().plot.bar(stacked=True)\n",
    "        plt.ylabel('Amount of cells')\n",
    "        plt.xlabel('Leiden cluster')\n",
    "       \n",
    "    return adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch Correction\n",
    "\n",
    "## Another function written to merge the samples with BBKNN\n",
    "\n",
    "# Clustering and Dimentional Reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BBKNN_clustering(adata,out_path, multi_sample, resol=2): \n",
    "    \n",
    "    # Calculate the visualizations\n",
    "    sc.pp.pca(adata, n_comps=50, use_highly_variable=True, svd_solver='arpack')\n",
    "    #sc.tl.pca(adata, svd_solver='arpack')\n",
    "    \n",
    "    if multi_sample:\n",
    "        No_combat = adata.copy()\n",
    "        sc.pp.neighbors(No_combat)\n",
    "        sc.tl.umap(No_combat)\n",
    "        bbknn.bbknn(adata,batch_key='Sample')\n",
    "    else:\n",
    "        sc.pp.neighbors(adata, n_neighbors=10, n_pcs=50)\n",
    "    sc.tl.leiden(adata,resolution=resol)\n",
    "    #sc.tl.louvain(adata,resolution=2)\n",
    "    sc.tl.paga(adata, groups='leiden')\n",
    "    #sc.tl.tsne(adata, n_jobs=40) #Note n_jobs works for MulticoreTSNE, but not regular implementation)\n",
    "    #sc.tl.diffmap(adata)\n",
    "    #sc.tl.draw_graph(adata)\n",
    "    sc.pl.paga(adata,node_size_power= 1.0,threshold=0.1 ,layout ='rt',edge_width_scale = 0.1,save ='_Graph.png') \n",
    "  \n",
    "    \n",
    "    # remove `plot=False` if you want to see the coarse-grained graph\n",
    "    sc.tl.umap(adata,  init_pos=sc.tl._utils.get_init_pos_from_paga(adata), maxiter=100, min_dist=0.1, spread= 4.0)\n",
    "    \n",
    "    sc.pl.umap(adata, color='leiden', legend_loc='on data',legend_fontsize=10,save ='_Leiden_clustering.png') \n",
    "  \n",
    "    \n",
    "    if multi_sample:\n",
    "        sc.pl.umap(No_combat, color='Sample',save ='_no_bbknn.png')\n",
    "        sc.pl.umap(adata, color='Sample',save ='_by_sample.png')\n",
    "        adata.obs.groupby(['leiden'])['Sample'].value_counts(normalize = True).unstack().plot.bar(stacked=True)\n",
    "        ax = plt.subplot(111)\n",
    "        plt.ylabel('Composition of cells')\n",
    "        plt.xlabel('Leiden cluster')\n",
    "        box = ax.get_position()\n",
    "        ax.set_position([box.x0, box.y0, box.width * 0.8, box.height])\n",
    "        ax.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "\n",
    "        adata.obs.groupby(['leiden'])['Sample'].value_counts().unstack().plot.bar(stacked=True)\n",
    "        plt.ylabel('Amount of cells')\n",
    "        plt.xlabel('Leiden cluster')\n",
    "\n",
    "    return adata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spatial Integration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Differential Expression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def differential(adata,out_path, multi_sample, top_n= 2,organism=\"hsapiens\"):\n",
    "    sc.tl.rank_genes_groups(adata, \"leiden\",use_raw=False, n_genes=adata.var_names.size)\n",
    "    sc.pl.rank_genes_groups(adata, key='rank_genes_groups', save = '_by_cluster.png')\n",
    "\n",
    "    rank_genes = pd.DataFrame(adata.uns['rank_genes_groups']['names'])\n",
    "    top_2 = list(set(sum(rank_genes.head(top_n).values.tolist(),[])))\n",
    "    rank_pavlues = pd.DataFrame(adata.uns['rank_genes_groups']['pvals'])\n",
    "    rank_pavlues.rename(columns=lambda x: x+'_pvals', inplace=True)\n",
    "    rank_fold = pd.DataFrame(adata.uns['rank_genes_groups']['logfoldchanges'])\n",
    "    rank_fold.rename(columns=lambda x: x+'_logfoldchanges', inplace=True)\n",
    "    pd.concat([rank_genes, rank_pavlues,rank_fold], axis=1, join='inner').to_csv(out_path+'/DE_genes_in_clusters.csv')\n",
    "\n",
    "    sc.pl.umap(adata,color=top_2,color_map= 'OrRd',save ='_top2_in_clusters.png')\n",
    "    sc.pl.rank_genes_groups_dotplot(adata,use_raw=False,save ='in_clusters.png')\n",
    "    sc.pl.rank_genes_groups_heatmap(adata,use_raw=False,standard_scale='var',dendrogram=True,save ='_in_clusters.png')\n",
    "    sc.pl.rank_genes_groups_matrixplot(adata,save ='in_clusters.png')\n",
    "    sc.pl.rank_genes_groups_stacked_violin(adata,save ='in_clusters.png')\n",
    "    sc.pl.rank_genes_groups_tracksplot(adata,n_genes = 2,save ='_in_clusters.png')\n",
    "    clusters = adata.obs['leiden'].unique().tolist()\n",
    "\n",
    "    for c in clusters:\n",
    "        q= rank_genes[c].head(200).tolist()\n",
    "        sc.queries.enrich(q, org=organism,gprofiler_kwargs={'no_evidences':False}).to_csv(out_path+'/cluster_'+c+'_within_cluster_enrichment.csv')\n",
    "    \n",
    "    if multi_sample:\n",
    "        sc.tl.rank_genes_groups(adata, \"Sample\",use_raw=False,key_added='rank_genes_samples', n_genes=adata.var_names.size)\n",
    "        sc.pl.rank_genes_groups(adata, key='rank_genes_samples', save = '_compare.png')\n",
    " \n",
    "    \n",
    "\n",
    "        rank_genes = pd.DataFrame(adata.uns['rank_genes_samples']['names'])\n",
    "        top_3 = list(set(sum(rank_genes.head(top_n).values.tolist(),[])))\n",
    "        rank_pavlues = pd.DataFrame(adata.uns['rank_genes_samples']['pvals'])\n",
    "        rank_pavlues.rename(columns=lambda x: x+'_pvals', inplace=True)\n",
    "        rank_fold = pd.DataFrame(adata.uns['rank_genes_samples']['logfoldchanges'])\n",
    "        rank_fold.rename(columns=lambda x: x+'_logfoldchanges', inplace=True)\n",
    "        pd.concat([rank_genes, rank_pavlues,rank_fold], axis=1, join='inner').to_csv(out_path+'/DE_genes_in_samples.csv')\n",
    "\n",
    "    return adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enrichment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Binarize_Anti(adata,antilist,out_path,sample_tag):\n",
    "    for a in antilist:\n",
    "        thres = Thrshold_by_Gaussian_with_plot(adata, a, out_path,  sample_tag,sparse = False)\n",
    "        data = adata.obs[a]\n",
    "        adata.obs[a+'_bin'] = np.where(data > thres[2], a, 'NAN')\n",
    "    return adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell Typing\n",
    "\n",
    "# Velocity\n",
    "# TCR/BCR\n",
    "# Pseudo time\n",
    "# Gene Regulatory Networks\n",
    "# Perturbation\n",
    "# Cell-Cell Communication\n",
    "# TCR/BCR\n",
    "# Ingestion\n",
    "# Gene/Condition corrrelation\n",
    "\n",
    "# Docx Report Generation\n",
    "# Cell Browser \n",
    "# Cirrocumulus\n",
    "# HTML Dashborad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
